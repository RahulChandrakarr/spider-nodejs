/* tslint:disable */
/* eslint-disable */

/* auto-generated by NAPI-RS */

/** a simple page object */
export interface NPage {
  /** the url found */
  url: string
  /** the content of the page found */
  content: string
}
/** crawl a website gathering all links to array */
export function crawl(url: string): Promise<NWebsite>
/** website main data from rust to node */
export class NWebsite {
  /** all of the website links. */
  links: Array<string>
  /** the pages found */
  pages: Array<NPage>
}
/** a website holding the inner spider::website::Website from Rust fit for nodejs */
export class Website {
  constructor(url: string)
  /** crawl a website */
  crawl(): Promise<void>
  /** scrape a website */
  scrape(): Promise<void>
  /** get all the links of a website */
  getLinks(): Array<string>
  /** get all the pages of a website - requires calling website.scrape */
  getPages(): Array<NPage>
  /** Set HTTP headers for request using [reqwest::header::HeaderMap](https://docs.rs/reqwest/latest/reqwest/header/struct.HeaderMap.html). */
  withHeaders(headers?: object | undefined | null): this
  /** Add user agent to request. */
  withUserAgent(userAgent?: string | undefined | null): this
  /** Respect robots.txt file. */
  withRespectRobotsTxt(respectRobotsTxt: boolean): this
  /** Include subdomains detection. */
  withSubdomains(subdomains: boolean): this
  /** Include tld detection. */
  withTld(tld: boolean): this
  /** Only use HTTP/2. */
  withHttp2PriorKnowledge(http2PriorKnowledge: boolean): this
  withBudget(budget?: Record<string, number> | undefined | null): this
  /** Delay between request as ms. */
  withDelay(delay: number): this
  /** Use proxies for request. */
  withProxies(proxies?: Array<string> | undefined | null): this
  /** build the inner website - not required for all builder_steps */
  build(): this
}
